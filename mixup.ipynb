{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c8d327f-01bc-4d67-ad93-a6730c3df2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import math\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ef68dd3-2f23-467f-8cd1-e986b068863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(img_size, dataset):\n",
    "    transform_mnist = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor()])\n",
    "    transform_other = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])\n",
    "    \n",
    "    if dataset == 'mnist':\n",
    "        train_data = datasets.__dict__[dataset.upper()](root='./data', train=True, transform=transform_mnist, download=True)\n",
    "        test_data = datasets.__dict__[dataset.upper()](root='./data', train=True, transform=transform_mnist, download=True)\n",
    "        in_ch = 1\n",
    "    elif dataset == 'cifar10':\n",
    "        train_data = datasets.__dict__[dataset.upper()](root='./data', train=True, transform=transform_other, download=True)\n",
    "        test_data = datasets.__dict__[dataset.upper()](root='./data', train=True, transform=transform_other, download=True)\n",
    "        in_ch = 3\n",
    "    elif dataset == 'svhn':\n",
    "        training_data = datasets.__dict__[dataset.upper()](root='./data', split='train', transform=transform_other, download=True)\n",
    "        test_data = datasets.__dict__[dataset.upper()](root='./data', split='test', transform=transform_other, download=True)\n",
    "        in_ch = 3\n",
    "    dataloader_train = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_test = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    return dataloader_train, dataloader_test, in_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e7cc5f-1094-4e23-914b-9e9cfd12da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_ch=3, n_cls=10, img_size=32):\n",
    "        super(CNN, self).__init__()\n",
    "        n_convs = int(np.log2(img_size)) - 1\n",
    "            \n",
    "        layers = []\n",
    "        out_ch = 16\n",
    "        for _ in range(n_convs):\n",
    "            layers.append(nn.Conv2d(in_ch, out_ch, 3, 1, 1))\n",
    "            layers.append(nn.BatchNorm2d(out_ch))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            layers.append(nn.MaxPool2d(2, 2))\n",
    "            in_ch = out_ch\n",
    "            out_ch = out_ch * 2\n",
    "        \n",
    "        self.hidden_layers = nn.Sequential(*layers)\n",
    "        fc_in = 2 * 2 * in_ch\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fc_in, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_cls))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.hidden_layers(x)\n",
    "        h_flat = h.flatten(start_dim=1)\n",
    "        out = self.classifier(h_flat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbb4d527-f445-4a08-8238-4144a2e057ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomLossFunction:\n",
    "    def __init__(self, reduction='mean'):\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def xent(self, x, t):\n",
    "        b, c = x.shape\n",
    "        x_log_softmax = torch.log_softmax(x, dim=1)\n",
    "        if self.reduction == 'mean':\n",
    "            loss = -torch.sum(t*x_log_softmax) / b\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = -torch.sum(t*x_log_softmax)\n",
    "        elif self.reduction == 'none':\n",
    "            loss = -torch.sum(t*x_log_softmax, keepdims=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30729de7-bf55-41ed-8bbd-f9de794a8894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "img_size = 32\n",
    "dataset = 'cifar10'\n",
    "lr = 0.1\n",
    "momentum = 0.9\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "dataloader_train, dataloader_test, in_ch = get_dataset(img_size, dataset)\n",
    "model = CNN(in_ch=in_ch, n_cls=10, img_size=img_size).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "cstm_lossfunc = CustomLossFunction()\n",
    "xent = nn.CrossEntropyLoss()\n",
    "iters = 0\n",
    "    \n",
    "scheduler = [int(epochs*0.5), int(epochs*0.75)]\n",
    "adjust_learning_rate = lr_scheduler.MultiStepLR(optimizer, scheduler, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40eb20ae-c1fa-473f-b72e-f78df09352e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.contiguous().view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].contiguous().view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3751f0e-bcc8-407b-80ba-bd79d10b6e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, dataloader, optimizer, cstm_lossfunc, iters):\n",
    "    model.train()\n",
    "    top1 = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    for idx, (data, tgt) in enumerate(dataloader):\n",
    "        data, tgt = data.to(device), tgt.to(device)\n",
    "        b = data.size(0)\n",
    "        gamma = np.random.beta(1,1)\n",
    "                \n",
    "        rand_idx = torch.randperm(b).to(device)\n",
    "        data_rand = data[rand_idx]\n",
    "        mixed_data = gamma * data + (1 - gamma) * data_rand\n",
    "            \n",
    "        onehot = torch.eye(10)[tgt].to(device)\n",
    "        onehot_rand = onehot[rand_idx]\n",
    "        mixed_tgt = gamma * onehot + (1 - gamma) * onehot_rand\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(mixed_data)\n",
    "        loss = cstm_lossfunc.xent(logits, mixed_tgt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        iters += 1\n",
    "        if idx % 100 == 0:\n",
    "            prec1 = accuracy(logits.data, tgt, topk=(1,))[0]\n",
    "            losses.update(loss.data.item(), b)\n",
    "            top1.update(prec1, b)\n",
    "            print('%d epochs [%d/%d]| loss: %.4f | acc: %.4f |' % (epoch, idx, len(dataloader), loss.item(), top1.avg))\n",
    "    return iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0906823c-7884-42c7-a662-a40290e9f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch, model, dataloader, xent):\n",
    "    model.eval()\n",
    "    top1 = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    for idx, (data, tgt) in enumerate(dataloader):\n",
    "        data, tgt = data.to(device), tgt.to(device)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            logits = model(data)\n",
    "                \n",
    "        loss = xent(logits, tgt)    \n",
    "        prec1 = accuracy(logits.data, tgt, topk=(1,))[0]\n",
    "        losses.update(loss.data.item(), data.size(0))\n",
    "        top1.update(prec1, data.size(0))\n",
    "    print('%d epochs | loss: %.4f | acc: %.4f |' % (epoch, loss.item(), top1.avg))\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327bd94-d934-46c6-9e83-42e747c292e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    iters = train(epoch, model, dataloader_train, optimizer, cstm_lossfunc, iters)\n",
    "    adjust_learning_rate.step()\n",
    "    test_acc = validation(epoch, model, dataloader_test, xent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2664cee7-0d8b-47ee-8527-81b50adfa91f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
